{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install opendatasets"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZMC1nBESdarP",
    "outputId": "1f8c862e-bd86-4024-8a95-61c1544caa02"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I21xxragvfy-",
    "outputId": "5cb39a11-8c46-4f07-dbf3-d3c2fa2ed2e4"
   },
   "source": [
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "import os\n",
    "od.download(\"https://www.kaggle.com/datasets/yehongjiang/pokemon-sprites-images\")\n",
    "pokemonData = pd.read_csv(\"pokemon_labels.csv\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "class PokemonDataset(Dataset):\n",
    "    def __init__(self, root_dir, dataframe, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        # Filter out rows where the folder is missing\n",
    "        valid_indices = []\n",
    "        invalid_ids = []\n",
    "        for idx in range(len(dataframe)):\n",
    "            row = dataframe.iloc[idx]\n",
    "            poke_id = str(row[\"id\"])\n",
    "            folder_found = False\n",
    "            for f in os.listdir(self.root_dir):\n",
    "                if f.startswith(f\"{poke_id}-\"):\n",
    "                    folder_found = True\n",
    "                    break\n",
    "            if folder_found:\n",
    "                valid_indices.append(idx)\n",
    "            else:\n",
    "                invalid_ids.append(poke_id)\n",
    "\n",
    "        self.df = dataframe.iloc[valid_indices].reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "        print(f\"Original dataset size: {len(dataframe)}\")\n",
    "        print(f\"Filtered dataset size: {len(self.df)}\")\n",
    "        print(f\"Number of entries filtered out: {len(invalid_ids)}\")\n",
    "        if invalid_ids:\n",
    "            print(f\"First 10 filtered IDs: {invalid_ids[:10]}\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        poke_id = str(row[\"id\"])\n",
    "\n",
    "        folder = None\n",
    "        for f in os.listdir(self.root_dir):\n",
    "            if f.startswith(f\"{poke_id}-\"):\n",
    "                folder = os.path.join(self.root_dir, f)\n",
    "                break\n",
    "\n",
    "        if folder is None:\n",
    "            # This should not happen after filtering, but keep for safety\n",
    "            raise FileNotFoundError(f\"Brak folderu dla id={poke_id}\")\n",
    "\n",
    "        sprite_dir = os.path.join(folder, \"front\", \"normal\")\n",
    "        files = [os.path.join(sprite_dir, fn) for fn in os.listdir(sprite_dir) if fn.endswith(\".png\")]\n",
    "        if len(files) == 0:\n",
    "            raise FileNotFoundError(f\"Brak sprite'Ã³w w {sprite_dir}\")\n",
    "\n",
    "        img_path = files[0]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = row.drop([\"id\", \"name\"]).values.astype(\"float32\")\n",
    "        label = torch.tensor(label)\n",
    "\n",
    "        return img, label"
   ],
   "metadata": {
    "id": "ouRb0Ut6dBXu"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "BT_boFWvvovW",
    "outputId": "462e303f-e6ba-46fb-d6c3-5156ef18bfa3"
   },
   "source": [
    "print(os.listdir(\"./pokemon-sprites-images/pokemon_images/sprites\")[:1000])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Xg3Qph-BcQok"
   },
   "source": [
    "def sinusoidal_embedding(timesteps: torch.LongTensor, dim: int):\n",
    "    \"\"\"\n",
    "    timesteps: (B,) long tensor\n",
    "    returns: (B, dim) float tensor\n",
    "    \"\"\"\n",
    "    assert len(timesteps.shape) == 1\n",
    "    device = timesteps.device\n",
    "    half = dim // 2\n",
    "    freqs = torch.exp(-torch.log(torch.tensor(10000.0, device=device)) * torch.arange(half, device=device) / (half - 1))\n",
    "    args = timesteps.float().unsqueeze(1) * freqs.unsqueeze(0)\n",
    "    emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "    if dim % 2 == 1:\n",
    "        emb = F.pad(emb, (0, 1))\n",
    "    return emb"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X2hgfDu1vqk9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9db7d143-94cc-4881-e510-4383f91f36c1"
   },
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize((96, 96), interpolation=Image.NEAREST),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "dataset = PokemonDataset(root_dir=\"./pokemon-sprites-images/pokemon_images/sprites\", dataframe = pokemonData, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JrJ4xy4BcQok"
   },
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard convolutional block with GroupNorm, SiLU activation,\n",
    "    a residual connection, and time embedding injection.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, time_emb_dim, is_res=True):\n",
    "        super().__init__()\n",
    "        self.is_res = is_res\n",
    "        self.main_path = nn.Sequential(\n",
    "            nn.GroupNorm(8, in_ch),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "        )\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_emb_dim, out_ch),\n",
    "        )\n",
    "        self.res_conv = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        h = self.main_path(x)\n",
    "        time_emb = self.time_mlp(temb).unsqueeze(-1).unsqueeze(-1)\n",
    "        h = h + time_emb\n",
    "        return h + self.res_conv(x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VKB4Df_ucQol"
   },
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Self-attention block. Applies Multi-Head Self-Attention to 2D feature maps.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.num_heads = num_heads\n",
    "        self.norm = nn.GroupNorm(8, channels)\n",
    "        self.qkv = nn.Conv2d(channels, channels * 3, 1, bias=False)\n",
    "        self.proj = nn.Conv2d(channels, channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = self.norm(x)\n",
    "        qkv = self.qkv(x).reshape(B, 3, self.num_heads, C // self.num_heads, H * W)\n",
    "        q, k, v = qkv.unbind(1)\n",
    "\n",
    "        attn = torch.einsum('b h c i, b h c j -> b h i j', q, k) * ((C // self.num_heads) ** -0.5)\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "\n",
    "        out = torch.einsum('b h i j, b h c j -> b h c i', attn, v)\n",
    "        out = out.reshape(B, C, H, W)\n",
    "        return x + self.proj(out)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PtkB2Ft9wJ5V"
   },
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, img_channels=3, base_channels=128, time_emb_dim=256, cond_dim = 47):\n",
    "        super().__init__()\n",
    "\n",
    "        # Sinusoidalne embeddingi\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(time_emb_dim, time_emb_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim),\n",
    "        )\n",
    "\n",
    "        # Wektor cech\n",
    "        self.cond_mlp = nn.Sequential(\n",
    "            nn.Linear(cond_dim, time_emb_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim),\n",
    "        )\n",
    "\n",
    "\n",
    "        ch_mults = (1, 2, 4, 8)\n",
    "        channels = [base_channels] + [base_channels * m for m in ch_mults]\n",
    "\n",
    "        self.init_conv = nn.Conv2d(img_channels, base_channels, 3, padding=1)\n",
    "\n",
    "        self.down_blocks = nn.ModuleList()\n",
    "        for i in range(len(ch_mults)):\n",
    "            in_ch = channels[i]\n",
    "            out_ch = channels[i+1]\n",
    "            self.down_blocks.append(nn.ModuleList([\n",
    "                ConvBlock(in_ch, out_ch, time_emb_dim),\n",
    "                AttentionBlock(out_ch) if i >= 2 else nn.Identity(),\n",
    "                nn.Conv2d(out_ch, out_ch, 4, stride=2, padding=1)\n",
    "            ]))\n",
    "\n",
    "        self.mid_block1 = ConvBlock(channels[-1], channels[-1], time_emb_dim)\n",
    "        self.mid_attn = AttentionBlock(channels[-1])\n",
    "        self.mid_block2 = ConvBlock(channels[-1], channels[-1], time_emb_dim)\n",
    "\n",
    "        self.up_blocks = nn.ModuleList()\n",
    "        for i in reversed(range(len(ch_mults))):\n",
    "            in_ch = channels[i+1]\n",
    "            out_ch = channels[i]\n",
    "\n",
    "            self.up_blocks.append(nn.ModuleList([\n",
    "                nn.ConvTranspose2d(in_ch, out_ch, 4, stride=2, padding=1),\n",
    "                ConvBlock(out_ch + in_ch, out_ch, time_emb_dim),\n",
    "                AttentionBlock(out_ch) if i >= 2 else nn.Identity(),\n",
    "            ]))\n",
    "\n",
    "        self.final_norm = nn.GroupNorm(8, base_channels)\n",
    "        self.final_act = nn.SiLU()\n",
    "        self.final_conv = nn.Conv2d(base_channels, img_channels, 1)\n",
    "\n",
    "    def forward(self, x, t, cond):\n",
    "        temb = sinusoidal_embedding(t, 256)\n",
    "        temb = self.time_mlp(temb)\n",
    "\n",
    "        cemb = self.cond_mlp(cond)\n",
    "        temb = temb + cemb\n",
    "        x = self.init_conv(x)\n",
    "\n",
    "        skips = [x]\n",
    "        for block, attn, downsample in self.down_blocks:\n",
    "            x = block(x, temb)\n",
    "            x = attn(x)\n",
    "            skips.append(x)\n",
    "            x = downsample(x)\n",
    "\n",
    "        x = self.mid_block1(x, temb)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x, temb)\n",
    "\n",
    "        for upsample, block, attn in self.up_blocks:\n",
    "            x = upsample(x)\n",
    "            skip = skips.pop()\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "            x = block(x, temb)\n",
    "            x = attn(x)\n",
    "\n",
    "        x = self.final_norm(x)\n",
    "        x = self.final_act(x)\n",
    "        return self.final_conv(x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JblbnsOcwOE1"
   },
   "source": [
    "class Diffusion:\n",
    "    def __init__(self, model: nn.Module, img_size=96, device=\"cuda\", timesteps=256):\n",
    "        self.model = model\n",
    "        self.img_size = img_size\n",
    "        self.device = device\n",
    "        self.timesteps = timesteps\n",
    "\n",
    "        betas = torch.linspace(1e-4, 0.02, timesteps, device=device)\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "\n",
    "        self.betas = betas\n",
    "        self.alphas = alphas\n",
    "        self.alphas_cumprod = alphas_cumprod\n",
    "        self.alphas_cumprod_prev = torch.cat([torch.tensor([1.0], device=device), alphas_cumprod[:-1]])\n",
    "\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1 - alphas_cumprod)\n",
    "        self.sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "\n",
    "    def q_sample(self, x0, t, noise=None):\n",
    "        \"\"\"\n",
    "        sample from q(x_t | x_0)\n",
    "        x0: (B,C,H,W)\n",
    "        t: (B,) long tensor\n",
    "        \"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x0)\n",
    "        sqrt_alpha_cumprod_t = self.sqrt_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "        sqrt_one_minus_alpha_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "        return sqrt_alpha_cumprod_t * x0 + sqrt_one_minus_alpha_cumprod_t * noise\n",
    "\n",
    "    def training_step(self, x0, cond):\n",
    "        \"\"\"\n",
    "        single batch training step: pick random t for each sample\n",
    "        returns MSE loss between predicted noise and real noise\n",
    "        \"\"\"\n",
    "        b = x0.size(0)\n",
    "        t = torch.randint(0, self.timesteps, (b,), device=self.device, dtype=torch.long)\n",
    "        noise = torch.randn_like(x0)\n",
    "        x_noisy = self.q_sample(x0, t, noise)\n",
    "        noise_pred = self.model(x_noisy, t, cond)\n",
    "        loss = F.mse_loss(noise_pred, noise)\n",
    "        return loss\n",
    "\n",
    "    def p_mean_variance(self, x_t, t, cond):\n",
    "        \"\"\"\n",
    "        computes posterior mean and variance for q(x_{t-1} | x_t, x0_pred)\n",
    "        x_t: (B,C,H,W)\n",
    "        t: scalar int or 0-d python int\n",
    "        returns: posterior_mean, posterior_variance (both tensors shape (B,C,H,W) for mean and (B,1,1,1) for var)\n",
    "        \"\"\"\n",
    "        B = x_t.shape[0]\n",
    "        device = x_t.device\n",
    "        t_tensor = torch.full((B,), t, device=device, dtype=torch.long)\n",
    "        eps_theta = self.model(x_t, t_tensor, cond)\n",
    "\n",
    "        sqrt_alpha_hat_t = self.sqrt_alphas_cumprod[t]\n",
    "        sqrt_one_minus_alpha_hat_t = self.sqrt_one_minus_alphas_cumprod[t]\n",
    "        x0_pred = (x_t - sqrt_one_minus_alpha_hat_t * eps_theta) / sqrt_alpha_hat_t\n",
    "        x0_pred = torch.clamp(x0_pred, -1.0, 1.0)\n",
    "\n",
    "        alpha_t = self.alphas[t]\n",
    "        alpha_hat_t = self.alphas_cumprod[t]\n",
    "        alpha_hat_prev = self.alphas_cumprod_prev[t]\n",
    "        beta_t = self.betas[t]\n",
    "\n",
    "        coef_x0 = (torch.sqrt(alpha_hat_prev) * beta_t) / (1.0 - alpha_hat_t)\n",
    "        coef_xt = (torch.sqrt(alpha_t) * (1.0 - alpha_hat_prev)) / (1.0 - alpha_hat_t)\n",
    "\n",
    "        coef_x0 = coef_x0.view(1, 1, 1, 1)\n",
    "        coef_xt = coef_xt.view(1, 1, 1, 1)\n",
    "\n",
    "        posterior_mean = coef_x0 * x0_pred + coef_xt * x_t\n",
    "        posterior_variance = beta_t * (1.0 - alpha_hat_prev) / (1.0 - alpha_hat_t)\n",
    "        posterior_log_variance = torch.log(torch.clamp(posterior_variance, min=1e-20)).view(1, 1, 1, 1)\n",
    "\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance\n",
    "\n",
    "    def p_sample(self, x_t, t, cond):\n",
    "        \"\"\"\n",
    "        sample x_{t-1} from p(x_{t-1} | x_t)\n",
    "        \"\"\"\n",
    "        mean, var, log_var = self.p_mean_variance(x_t, t, cond)\n",
    "        if t == 0:\n",
    "            return mean\n",
    "        noise = torch.randn_like(x_t)\n",
    "        return mean + torch.sqrt(var).view(1,1,1,1) * noise\n",
    "\n",
    "    def sample(self, cond, batch_size=8):\n",
    "        \"\"\"\n",
    "        Full sampling loop: start from x_T ~ N(0,I), run p_sample iteratively.\n",
    "        \"\"\"\n",
    "        x = torch.randn(batch_size, 3, self.img_size, self.img_size, device=self.device)\n",
    "        for t in reversed(range(self.timesteps)):\n",
    "            x = self.p_sample(x, t, cond)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ArzdWMw9cQom"
   },
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = UNet(img_channels=3, base_channels=128, time_emb_dim=256).to(device)\n",
    "diffusion = Diffusion(model, img_size=96, device=device, timesteps=1000)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 962
    },
    "id": "ofmzb66rcQon",
    "outputId": "07164a51-a51e-492b-9ae0-c87270bd571e"
   },
   "source": [
    "img, _ = next(iter(dataloader))\n",
    "print(torch.unique(img))\n",
    "plt.imshow(img[0].permute(1, 2, 0).cpu().numpy())\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cc58f83b"
   },
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hsw0bLLVwQ01",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "6221099d-eb36-484b-c73a-6bd47e8243fc"
   },
   "source": [
    "num_epochs = 3500\n",
    "iters = 0\n",
    "for epoch in range(num_epochs):\n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for imgs, cond in pbar:\n",
    "        imgs = imgs.to(device)\n",
    "        cond = cond.to(device)\n",
    "        loss = diffusion.training_step(imgs, cond)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        iters += 1\n",
    "        pbar.set_postfix({\"loss\": loss.item(), \"iters\": iters})\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, cond_batch = next(iter(dataloader))\n",
    "            cond_batch = cond_batch[:8].to(device)\n",
    "\n",
    "            samples = diffusion.sample(cond = cond_batch, batch_size=8)\n",
    "            samples = (samples * 0.5 + 0.5).clamp(0, 1)\n",
    "        model.train()\n",
    "\n",
    "        fig, axes = plt.subplots(1, 8, figsize=(16, 2))\n",
    "        for i in range(8):\n",
    "            img = samples[i].permute(1, 2, 0).cpu().numpy()\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].axis(\"off\")\n",
    "        plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. legendary, 2. mega_evolution, 3. alolan_form, 4. galarian_form, 5. gigantamax, 6. Bug, 7. Dark, 8. Dragon, 9. Electric, 10. Fairy, 11. Fighting, 12. Fire, 13. Flying, 14. Ghost, 15. Grass, 16. Ground, 17. Ice, 18. Normal, 19. Poison, 20. Psychic,\n",
    "# 21. Rock, 22. Steel, 23. Water, 24. shape_Armor, 25. shape_Arms, 26. shape_Ball, 27. shape_Blob, 28. shape_Bug-Wings, 29. shape_Fish, 30. shape_Heads, 31. shape_Humanoid, 32. shape_Legs, 33. shape_Quadruped, 34. shape_Squiggle, 35. shape_Tentacles, 36. shape_Upright, 37. shape_Wings, 38. color_Black, 39. color_Blue, 40. color_Brown,\n",
    "# 41. color_Gray, 42. color_Green, 43. color_Pink, 44. color_Purple, 45. color_Red, 46. color_White, 47. color_Yellow"
   ],
   "metadata": {
    "id": "Rb9yIJoV1T8m"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "feature_names = [\"legendary\", \"mega_evolution\", \"alolan_form\", \"galarian_form\", \"gigantamax\",\n",
    "                 \"Bug\", \"Dark\", \"Dragon\", \"Electric\", \"Fairy\",\n",
    "                 \"Fighting\", \"Fire\", \"Flying\", \"Ghost\", \"Grass\",\n",
    "                 \"Ground\", \"Ice\", \"Normal\", \"Poison\", \"Psychic\",\n",
    "                 \"Rock\", \"Steel\", \"Water\", \"shape_Armor\", \"shape_Arms\",\n",
    "                 \"shape_Ball\", \"shape_Blob\", \"shape_Bug-Wings\", \"shape_Fish\", \"shape_Heads\",\n",
    "                 \"shape_Humanoid\", \"shape_Legs\", \"shape_Quadruped\", \"shape_Squiggle\", \"shape_Tentacles\",\n",
    "                 \"shape_Upright\", \"shape_Wings\", \"color_Black\", \"color_Blue\", \"color_Brown\",\n",
    "                 \"color_Gray\", \"color_Green\", \"color_Pink\", \"color_Purple\", \"color_Red\",\n",
    "                 \"color_White\", \"color_Yellow\"]\n",
    "cond_dim = len(feature_names)\n",
    "batch_size = 4\n",
    "\n",
    "cond_batch = torch.zeros(batch_size, cond_dim)\n",
    "\n",
    "cond_batch[0, [14,18,32,41]] = 1\n",
    "cond_batch[1, [0,12,23,46]] = 1\n",
    "cond_batch[2, [0]]   = 1\n",
    "cond_batch[3, [5,8,13,31]] = 1\n",
    "\n",
    "cond_batch = cond_batch.to(device)"
   ],
   "metadata": {
    "id": "b3WU0Oc63L7f"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    samples = diffusion.sample(cond=cond_batch, batch_size=batch_size)\n",
    "    samples = (samples * 0.5 + 0.5).clamp(0, 1)"
   ],
   "metadata": {
    "id": "dNxtG3W17itY"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1, batch_size, figsize=(16, 2))\n",
    "for i in range(batch_size):\n",
    "    axes[i].imshow(samples[i].permute(1, 2, 0).cpu().numpy())\n",
    "    axes[i].axis(\"off\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "-SDFVGuk7tFg",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "outputId": "192db232-4433-43e8-cf50-f623a710bfd3"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Xx2qol34cQon",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "outputId": "efe41b01-b34a-4896-aabd-cbd69da6b480"
   },
   "source": [
    "with torch.no_grad():\n",
    "    _, cond_batch = next(iter(dataloader))\n",
    "    cond_batch = cond_batch[:8].to(device)\n",
    "\n",
    "    samples = diffusion.sample(cond=cond_batch, batch_size=8)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 8, figsize=(16, 2))\n",
    "    for i in range(8):\n",
    "        axes[i].imshow(samples[i].permute(1, 2, 0).cpu().numpy())\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "RctVFHAa0Ur1"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2TEY-QaXcQon"
   },
   "source": [
    "torch.save(model.state_dict(), \"unet_pokemon_diffusion.pth\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
